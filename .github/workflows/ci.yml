name: CI

on:
  pull_request:
  push:
    branches: [main]

permissions:
  contents: read
  pull-requests: write
  id-token: write

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Validate YAML workflows
        run: |
          echo "Validating workflow YAML files..."
          for file in .github/workflows/*.yml; do
            echo "Checking $file"
            python3 -c "import yaml; yaml.safe_load(open('$file'))" || exit 1
          done
          echo "All workflow files are valid YAML"

      - name: Shellcheck scripts in workflows
        run: |
          echo "Checking for shell script issues in workflows..."
          # Extract and check run blocks from workflows
          # This is a basic check - shellcheck would be better but requires install
          for file in .github/workflows/*.yml; do
            echo "Scanning $file for common issues..."
            # Check for unsafe variable interpolation (the bug we fixed)
            if grep -E "='\\$\\{\\{.*\\}\\}'" "$file"; then
              echo "WARNING: Found potentially unsafe variable interpolation in $file"
              echo "Use env: block + file writes instead"
              exit 1
            fi
          done
          echo "No obvious shell issues found"

      - name: Validate prompt files exist
        run: |
          echo "Checking required prompt files..."
          test -f .github/prompts/analyze-release.md || (echo "Missing analyze-release.md" && exit 1)
          test -f .github/prompts/analyze-community.md || (echo "Missing analyze-community.md" && exit 1)
          echo "All prompt files present"

      - name: Validate state files
        run: |
          echo "Checking state files..."
          test -f .github/last-checked-version.txt || (echo "Missing last-checked-version.txt" && exit 1)
          test -f .github/last-community-scan.txt || (echo "Missing last-community-scan.txt" && exit 1)
          echo "All state files present"

      - name: Run version logic tests
        run: ./tests/test-version-logic.sh

      - name: Run analysis schema tests
        run: ./tests/test-analysis-schema.sh

      - name: Run workflow trigger tests
        run: ./tests/test-workflow-triggers.sh

      - name: Validate E2E fixtures and scenarios
        run: ./tests/e2e/run-simulation.sh

  # Clean up old bot comments on PR push (keeps PRs tidy)
  cleanup-old-comments:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - name: Resolve outdated bot comments
        uses: int128/hide-comment-action@v1
        with:
          # Hide (collapse) old bot comments when new push arrives
          # Human comments are preserved
          authors: 'github-actions[bot]'
          starts-with: |
            ## E2E SDLC Evaluation
            ## E2E Before/After Comparison
            ## PR Code Review
            **Claude finished

  # TIER 1: Quick E2E Check - Runs on every PR commit
  # Single comparison: baseline vs candidate (1x each)
  # Purpose: Fast quality gate to catch regressions early
  e2e-quick-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    needs: [validate, cleanup-old-comments]

    steps:
      - name: Checkout PR branch
        uses: actions/checkout@v4
        with:
          path: pr-branch

      - name: Checkout main branch for baseline
        uses: actions/checkout@v4
        with:
          ref: main
          path: main-branch

      - name: Check if baseline wizard exists
        id: check-baseline
        run: |
          if [ -d "main-branch/.claude/hooks" ] || [ -d "main-branch/.claude/skills" ]; then
            echo "has_baseline=true" >> $GITHUB_OUTPUT
            echo "✓ Baseline wizard found in main branch"
          else
            echo "has_baseline=false" >> $GITHUB_OUTPUT
            echo "⚠️ BOOTSTRAPPING: No wizard in main branch (first installation)"
          fi

      - name: Install BASELINE wizard (main branch) into test fixture
        if: steps.check-baseline.outputs.has_baseline == 'true'
        run: |
          echo "Installing main branch wizard into test fixture..."
          # Create .claude directory in test fixture
          mkdir -p pr-branch/tests/e2e/fixtures/test-repo/.claude
          # Copy main branch wizard files
          cp -r main-branch/.claude/hooks pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp -r main-branch/.claude/skills pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp main-branch/.claude/settings.json pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          echo "Baseline wizard installed:"
          ls -la pr-branch/tests/e2e/fixtures/test-repo/.claude/ || echo "No .claude directory"

      - name: Run BASELINE simulation with Claude
        if: steps.check-baseline.outputs.has_baseline == 'true'
        id: baseline
        uses: anthropics/claude-code-action@v1
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          claude_args: |
            --max-turns 30
            --allowedTools "Read,Edit,Write,Bash(npm *),Bash(node *)"
            --add-dir pr-branch/tests/e2e
          prompt: |
            Run an E2E SDLC simulation.

            Working directory: pr-branch/tests/e2e/fixtures/test-repo
            Scenario file: pr-branch/tests/e2e/scenarios/medium-add-feature.md

            1. Read the scenario file to understand the task
            2. Execute the scenario task following SDLC principles
            3. Return results as JSON with score

            After execution, output a summary of what you did and whether SDLC was followed.

      - name: Evaluate BASELINE
        if: steps.check-baseline.outputs.has_baseline == 'true'
        id: eval-baseline
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        working-directory: pr-branch
        run: |
          OUTPUT_FILE="/home/runner/work/_temp/claude-execution-output.json"
          SCENARIO="tests/e2e/scenarios/medium-add-feature.md"

          if [ ! -f "$OUTPUT_FILE" ]; then
            echo "baseline_score=0" >> $GITHUB_OUTPUT
            echo "baseline_status=fail" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Run evaluation
          RESULT=$(./tests/e2e/evaluate.sh "$SCENARIO" "$OUTPUT_FILE" --json 2>&1) || true

          if echo "$RESULT" | jq -e '.score' > /dev/null 2>&1; then
            SCORE=$(echo "$RESULT" | jq -r '.score // 0')
          else
            SCORE="0"
          fi

          echo "Baseline score: $SCORE"
          echo "baseline_score=$SCORE" >> $GITHUB_OUTPUT

          # Save output for comparison
          cp "$OUTPUT_FILE" "/tmp/baseline-output.json" 2>/dev/null || true

      - name: Reset test fixture for CANDIDATE
        if: steps.check-baseline.outputs.has_baseline == 'true'
        run: |
          echo "Resetting test fixture..."
          cd pr-branch/tests/e2e/fixtures/test-repo
          # Remove any changes Claude made
          git checkout -- . 2>/dev/null || true
          git clean -fd 2>/dev/null || true
          # Remove old wizard
          rm -rf .claude

      - name: Install CANDIDATE wizard (PR branch) into test fixture
        run: |
          echo "Installing PR branch wizard into test fixture..."
          mkdir -p pr-branch/tests/e2e/fixtures/test-repo/.claude
          # Copy PR branch wizard files
          cp -r pr-branch/.claude/hooks pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp -r pr-branch/.claude/skills pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp pr-branch/.claude/settings.json pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          echo "Candidate wizard installed:"
          ls -la pr-branch/tests/e2e/fixtures/test-repo/.claude/ || echo "No .claude directory"

      - name: Run CANDIDATE simulation with Claude
        id: candidate
        uses: anthropics/claude-code-action@v1
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          claude_args: |
            --max-turns 30
            --allowedTools "Read,Edit,Write,Bash(npm *),Bash(node *)"
            --add-dir pr-branch/tests/e2e
          prompt: |
            Run an E2E SDLC simulation.

            Working directory: pr-branch/tests/e2e/fixtures/test-repo
            Scenario file: pr-branch/tests/e2e/scenarios/medium-add-feature.md

            1. Read the scenario file to understand the task
            2. Execute the scenario task following SDLC principles
            3. Return results as JSON with score

            After execution, output a summary of what you did and whether SDLC was followed.

      - name: Evaluate CANDIDATE
        id: eval-candidate
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        working-directory: pr-branch
        run: |
          OUTPUT_FILE="/home/runner/work/_temp/claude-execution-output.json"
          SCENARIO="tests/e2e/scenarios/medium-add-feature.md"

          if [ ! -f "$OUTPUT_FILE" ]; then
            echo "candidate_score=0" >> $GITHUB_OUTPUT
            echo "candidate_status=fail" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Run evaluation
          RESULT=$(./tests/e2e/evaluate.sh "$SCENARIO" "$OUTPUT_FILE" --json 2>&1) || true

          if echo "$RESULT" | jq -e '.score' > /dev/null 2>&1; then
            SCORE=$(echo "$RESULT" | jq -r '.score // 0')
          else
            SCORE="0"
          fi

          echo "Candidate score: $SCORE"
          echo "candidate_score=$SCORE" >> $GITHUB_OUTPUT

      - name: Compare scores
        id: compare
        run: |
          HAS_BASELINE="${{ steps.check-baseline.outputs.has_baseline }}"
          CANDIDATE="${{ steps.eval-candidate.outputs.candidate_score }}"
          CANDIDATE=${CANDIDATE:-0}

          # Handle bootstrapping scenario (no baseline wizard in main)
          if [ "$HAS_BASELINE" != "true" ]; then
            echo "BOOTSTRAPPING: No baseline wizard to compare against"
            echo "is_bootstrapping=true" >> $GITHUB_OUTPUT
            echo "baseline=N/A" >> $GITHUB_OUTPUT
            echo "candidate=$CANDIDATE" >> $GITHUB_OUTPUT
            echo "delta=N/A" >> $GITHUB_OUTPUT
            echo "status=BOOTSTRAPPING" >> $GITHUB_OUTPUT
            echo "emoji=:seedling:" >> $GITHUB_OUTPUT
            echo "pass=true" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "is_bootstrapping=false" >> $GITHUB_OUTPUT
          BASELINE="${{ steps.eval-baseline.outputs.baseline_score }}"
          BASELINE=${BASELINE:-0}

          # Calculate delta using bc for float math
          DELTA=$(echo "$CANDIDATE - $BASELINE" | bc -l)
          DELTA_FORMATTED=$(printf "%.1f" "$DELTA")

          echo "Baseline: $BASELINE"
          echo "Candidate: $CANDIDATE"
          echo "Delta: $DELTA_FORMATTED"

          # Determine status
          if [ "$(echo "$DELTA >= 0" | bc -l)" -eq 1 ]; then
            if [ "$(echo "$DELTA > 0" | bc -l)" -eq 1 ]; then
              STATUS="IMPROVED"
              EMOJI=":arrow_up:"
            else
              STATUS="UNCHANGED"
              EMOJI=":white_check_mark:"
            fi
            PASS="true"
          else
            # Check if regression is significant (> 0.5 points)
            if [ "$(echo "$DELTA < -0.5" | bc -l)" -eq 1 ]; then
              STATUS="REGRESSION"
              EMOJI=":x:"
              PASS="false"
            else
              STATUS="MINOR_DIP"
              EMOJI=":warning:"
              PASS="true"  # Minor dips within variance are acceptable
            fi
          fi

          echo "baseline=$BASELINE" >> $GITHUB_OUTPUT
          echo "candidate=$CANDIDATE" >> $GITHUB_OUTPUT
          echo "delta=$DELTA_FORMATTED" >> $GITHUB_OUTPUT
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "emoji=$EMOJI" >> $GITHUB_OUTPUT
          echo "pass=$PASS" >> $GITHUB_OUTPUT

      - name: Comment quick check results on PR
        uses: actions/github-script@v7
        with:
          script: |
            const isBootstrapping = '${{ steps.compare.outputs.is_bootstrapping }}' === 'true';
            const baseline = '${{ steps.compare.outputs.baseline }}';
            const candidate = '${{ steps.compare.outputs.candidate }}';
            const delta = '${{ steps.compare.outputs.delta }}';
            const status = '${{ steps.compare.outputs.status }}';
            const emoji = '${{ steps.compare.outputs.emoji }}';
            const pass = '${{ steps.compare.outputs.pass }}' === 'true';

            let body;

            if (isBootstrapping) {
              // Bootstrapping: first wizard installation, no baseline to compare
              body = [
                `## E2E Quick Check (Tier 1) ${emoji}`,
                '',
                '_First wizard installation - no baseline to compare against._',
                '',
                '| Metric | Value |',
                '|--------|-------|',
                `| Baseline (main) | N/A (no wizard yet) |`,
                `| Candidate (PR) | ${candidate} / 10 |`,
                `| Status | **BOOTSTRAPPING** |`,
                '',
                `### Result: First wizard installation verified`,
                '',
                'This PR introduces the wizard for the first time. After merge, future PRs will have a baseline to compare against.',
                '',
                '_Add `merge-ready` label for full evaluation before merge._',
                '',
                '---',
                '*Bootstrapping mode: Candidate-only evaluation (no baseline exists).*'
              ].join('\n');
            } else {
              // Normal comparison mode
              const statusText = {
                'IMPROVED': 'Wizard changes IMPROVED SDLC compliance!',
                'UNCHANGED': 'No change in SDLC compliance (stable)',
                'MINOR_DIP': 'Minor variance detected (within acceptable range)',
                'REGRESSION': 'REGRESSION: Wizard changes reduced SDLC compliance'
              }[status] || status;

              body = [
                `## E2E Quick Check (Tier 1) ${emoji}`,
                '',
                '_Fast quality gate - single comparison per commit._',
                '',
                '| Metric | Value |',
                '|--------|-------|',
                `| Baseline (main) | ${baseline} / 10 |`,
                `| Candidate (PR) | ${candidate} / 10 |`,
                `| Delta | ${delta >= 0 ? '+' : ''}${delta} |`,
                `| Status | **${status}** |`,
                '',
                `### Result: ${statusText}`,
                '',
                '_Add `merge-ready` label for full 3x evaluation before merge._',
                '',
                '---',
                '*Tier 1: 1x run each. Tier 2: 3x runs averaged for statistical confidence.*'
              ].join('\n');
            }

            github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });

      - name: Fail on regression
        if: steps.compare.outputs.pass != 'true'
        run: |
          echo "E2E quick check detected a regression"
          echo "Baseline: ${{ steps.compare.outputs.baseline }}"
          echo "Candidate: ${{ steps.compare.outputs.candidate }}"
          echo "Delta: ${{ steps.compare.outputs.delta }}"
          exit 1

  # TIER 2: Full E2E Evaluation - Runs before merge
  # 3x evaluations each, averaged for statistical confidence
  # Triggered by: merge-ready label
  e2e-full-evaluation:
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'pull_request' &&
      contains(github.event.pull_request.labels.*.name, 'merge-ready')
    needs: [validate, cleanup-old-comments]

    steps:
      - name: Checkout PR branch
        uses: actions/checkout@v4
        with:
          path: pr-branch

      - name: Checkout main branch for baseline
        uses: actions/checkout@v4
        with:
          ref: main
          path: main-branch

      - name: Check if baseline wizard exists
        id: check-baseline
        run: |
          if [ -d "main-branch/.claude/hooks" ] || [ -d "main-branch/.claude/skills" ]; then
            echo "has_baseline=true" >> $GITHUB_OUTPUT
            echo "✓ Baseline wizard found in main branch"
          else
            echo "has_baseline=false" >> $GITHUB_OUTPUT
            echo "⚠️ BOOTSTRAPPING: No wizard in main branch (first installation)"
          fi

      - name: Install BASELINE wizard (main branch) into test fixture
        if: steps.check-baseline.outputs.has_baseline == 'true'
        run: |
          echo "Installing main branch wizard into test fixture..."
          mkdir -p pr-branch/tests/e2e/fixtures/test-repo/.claude
          cp -r main-branch/.claude/hooks pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp -r main-branch/.claude/skills pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp main-branch/.claude/settings.json pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true

      - name: Run BASELINE simulation with Claude
        if: steps.check-baseline.outputs.has_baseline == 'true'
        id: baseline
        uses: anthropics/claude-code-action@v1
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          claude_args: |
            --max-turns 30
            --allowedTools "Read,Edit,Write,Bash(npm *),Bash(node *)"
            --add-dir pr-branch/tests/e2e
          prompt: |
            Run an E2E SDLC simulation.

            Working directory: pr-branch/tests/e2e/fixtures/test-repo
            Scenario file: pr-branch/tests/e2e/scenarios/medium-add-feature.md

            1. Read the scenario file to understand the task
            2. Execute the scenario task following SDLC principles
            3. Return results as JSON with score

            After execution, output a summary of what you did and whether SDLC was followed.

      - name: Evaluate BASELINE (5x for statistical power)
        if: steps.check-baseline.outputs.has_baseline == 'true'
        id: eval-baseline
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        working-directory: pr-branch
        run: |
          OUTPUT_FILE="/home/runner/work/_temp/claude-execution-output.json"
          SCENARIO="tests/e2e/scenarios/medium-add-feature.md"

          # Source stats library for confidence interval calculation
          source tests/e2e/lib/stats.sh

          if [ ! -f "$OUTPUT_FILE" ]; then
            echo "baseline_score=0" >> $GITHUB_OUTPUT
            echo "baseline_scores=0 0 0 0 0" >> $GITHUB_OUTPUT
            echo "baseline_ci=0 (no data)" >> $GITHUB_OUTPUT
            echo "baseline_ci_lower=0" >> $GITHUB_OUTPUT
            echo "baseline_ci_upper=0" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Run evaluation 5x for statistical power (t-distribution)
          echo "Running baseline evaluation 5 times..."
          SCORES=""
          for i in 1 2 3 4 5; do
            echo "Baseline evaluation run $i/5..."
            RESULT=$(./tests/e2e/evaluate.sh "$SCENARIO" "$OUTPUT_FILE" --json 2>&1) || true
            if echo "$RESULT" | jq -e '.score' > /dev/null 2>&1; then
              SCORE=$(echo "$RESULT" | jq -r '.score // 0')
            else
              SCORE="0"
            fi
            SCORES="$SCORES $SCORE"
            echo "  Run $i score: $SCORE"
            sleep 1
          done

          SCORES_DISPLAY=$(echo "$SCORES" | sed 's/^ //')

          # Calculate 95% confidence interval
          CI_RESULT=$(calculate_confidence_interval "$SCORES_DISPLAY")
          AVG=$(get_mean "$SCORES_DISPLAY")
          CI_LOWER=$(get_ci_lower "$SCORES_DISPLAY")
          CI_UPPER=$(get_ci_upper "$SCORES_DISPLAY")

          echo "Baseline: $CI_RESULT from [$SCORES_DISPLAY]"
          echo "baseline_score=$AVG" >> $GITHUB_OUTPUT
          echo "baseline_scores=$SCORES_DISPLAY" >> $GITHUB_OUTPUT
          echo "baseline_ci=$CI_RESULT" >> $GITHUB_OUTPUT
          echo "baseline_ci_lower=$CI_LOWER" >> $GITHUB_OUTPUT
          echo "baseline_ci_upper=$CI_UPPER" >> $GITHUB_OUTPUT

          cp "$OUTPUT_FILE" "/tmp/baseline-output.json" 2>/dev/null || true

      - name: Reset test fixture for CANDIDATE
        if: steps.check-baseline.outputs.has_baseline == 'true'
        run: |
          cd pr-branch/tests/e2e/fixtures/test-repo
          git checkout -- . 2>/dev/null || true
          git clean -fd 2>/dev/null || true
          rm -rf .claude

      - name: Install CANDIDATE wizard (PR branch) into test fixture
        run: |
          mkdir -p pr-branch/tests/e2e/fixtures/test-repo/.claude
          cp -r pr-branch/.claude/hooks pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp -r pr-branch/.claude/skills pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp pr-branch/.claude/settings.json pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true

      - name: Run CANDIDATE simulation with Claude
        id: candidate
        uses: anthropics/claude-code-action@v1
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          claude_args: |
            --max-turns 30
            --allowedTools "Read,Edit,Write,Bash(npm *),Bash(node *)"
            --add-dir pr-branch/tests/e2e
          prompt: |
            Run an E2E SDLC simulation.

            Working directory: pr-branch/tests/e2e/fixtures/test-repo
            Scenario file: pr-branch/tests/e2e/scenarios/medium-add-feature.md

            1. Read the scenario file to understand the task
            2. Execute the scenario task following SDLC principles
            3. Return results as JSON with score

            After execution, output a summary of what you did and whether SDLC was followed.

      - name: Evaluate CANDIDATE (5x for statistical power)
        id: eval-candidate
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        working-directory: pr-branch
        run: |
          OUTPUT_FILE="/home/runner/work/_temp/claude-execution-output.json"
          SCENARIO="tests/e2e/scenarios/medium-add-feature.md"

          # Source stats library for confidence interval calculation
          source tests/e2e/lib/stats.sh

          if [ ! -f "$OUTPUT_FILE" ]; then
            echo "candidate_score=0" >> $GITHUB_OUTPUT
            echo "candidate_scores=0 0 0 0 0" >> $GITHUB_OUTPUT
            echo "candidate_ci=0 (no data)" >> $GITHUB_OUTPUT
            echo "candidate_ci_lower=0" >> $GITHUB_OUTPUT
            echo "candidate_ci_upper=0" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Run evaluation 5x for statistical power (t-distribution)
          echo "Running candidate evaluation 5 times..."
          SCORES=""
          LAST_RESULT=""
          for i in 1 2 3 4 5; do
            echo "Candidate evaluation run $i/5..."
            RESULT=$(./tests/e2e/evaluate.sh "$SCENARIO" "$OUTPUT_FILE" --json 2>&1) || true
            if echo "$RESULT" | jq -e '.score' > /dev/null 2>&1; then
              SCORE=$(echo "$RESULT" | jq -r '.score // 0')
            else
              SCORE="0"
            fi
            SCORES="$SCORES $SCORE"
            LAST_RESULT="$RESULT"
            echo "  Run $i score: $SCORE"
            sleep 1
          done

          SCORES_DISPLAY=$(echo "$SCORES" | sed 's/^ //')

          # Calculate 95% confidence interval
          CI_RESULT=$(calculate_confidence_interval "$SCORES_DISPLAY")
          AVG=$(get_mean "$SCORES_DISPLAY")
          CI_LOWER=$(get_ci_lower "$SCORES_DISPLAY")
          CI_UPPER=$(get_ci_upper "$SCORES_DISPLAY")

          echo "Candidate: $CI_RESULT from [$SCORES_DISPLAY]"
          echo "candidate_score=$AVG" >> $GITHUB_OUTPUT
          echo "candidate_scores=$SCORES_DISPLAY" >> $GITHUB_OUTPUT
          echo "candidate_ci=$CI_RESULT" >> $GITHUB_OUTPUT
          echo "candidate_ci_lower=$CI_LOWER" >> $GITHUB_OUTPUT
          echo "candidate_ci_upper=$CI_UPPER" >> $GITHUB_OUTPUT

          # Extract criteria breakdown from last result
          CRITERIA=$(echo "$LAST_RESULT" | jq -r '.criteria | to_entries | map("- **\(.key)**: \(.value.points)/\(.value.max)") | join("\n")' 2>/dev/null || echo "Could not parse criteria")
          {
            echo "criteria<<EOF"
            echo "$CRITERIA"
            echo "EOF"
          } >> $GITHUB_OUTPUT

      - name: Compare scores (full evaluation with CI)
        id: compare
        working-directory: pr-branch
        run: |
          # Source stats library for CI comparison
          source tests/e2e/lib/stats.sh

          HAS_BASELINE="${{ steps.check-baseline.outputs.has_baseline }}"
          CANDIDATE="${{ steps.eval-candidate.outputs.candidate_score }}"
          CANDIDATE_CI="${{ steps.eval-candidate.outputs.candidate_ci }}"
          CANDIDATE_CI_LOWER="${{ steps.eval-candidate.outputs.candidate_ci_lower }}"
          CANDIDATE_CI_UPPER="${{ steps.eval-candidate.outputs.candidate_ci_upper }}"
          CANDIDATE_SCORES="${{ steps.eval-candidate.outputs.candidate_scores }}"
          CANDIDATE=${CANDIDATE:-0}

          # Handle bootstrapping scenario (no baseline wizard in main)
          if [ "$HAS_BASELINE" != "true" ]; then
            echo "BOOTSTRAPPING: No baseline wizard to compare against"
            echo "is_bootstrapping=true" >> $GITHUB_OUTPUT
            echo "baseline=N/A" >> $GITHUB_OUTPUT
            echo "baseline_ci=N/A" >> $GITHUB_OUTPUT
            echo "baseline_ci_lower=N/A" >> $GITHUB_OUTPUT
            echo "baseline_ci_upper=N/A" >> $GITHUB_OUTPUT
            echo "candidate=$CANDIDATE" >> $GITHUB_OUTPUT
            echo "candidate_ci=$CANDIDATE_CI" >> $GITHUB_OUTPUT
            echo "candidate_ci_lower=$CANDIDATE_CI_LOWER" >> $GITHUB_OUTPUT
            echo "candidate_ci_upper=$CANDIDATE_CI_UPPER" >> $GITHUB_OUTPUT
            echo "delta=N/A" >> $GITHUB_OUTPUT
            echo "status=BOOTSTRAPPING" >> $GITHUB_OUTPUT
            echo "emoji=:seedling:" >> $GITHUB_OUTPUT
            echo "pass=true" >> $GITHUB_OUTPUT
            echo "verdict=First wizard installation - no baseline to compare" >> $GITHUB_OUTPUT
            exit 0
          fi

          echo "is_bootstrapping=false" >> $GITHUB_OUTPUT
          BASELINE="${{ steps.eval-baseline.outputs.baseline_score }}"
          BASELINE_CI="${{ steps.eval-baseline.outputs.baseline_ci }}"
          BASELINE_CI_LOWER="${{ steps.eval-baseline.outputs.baseline_ci_lower }}"
          BASELINE_CI_UPPER="${{ steps.eval-baseline.outputs.baseline_ci_upper }}"
          BASELINE_SCORES="${{ steps.eval-baseline.outputs.baseline_scores }}"
          BASELINE=${BASELINE:-0}

          DELTA=$(echo "$CANDIDATE - $BASELINE" | bc -l)
          DELTA_FORMATTED=$(printf "%.1f" "$DELTA")

          echo "Baseline: $BASELINE_CI"
          echo "Candidate: $CANDIDATE_CI"
          echo "Delta: $DELTA_FORMATTED"

          # Use statistical CI comparison for verdict
          STAT_VERDICT=$(compare_ci "$BASELINE_SCORES" "$CANDIDATE_SCORES")

          case "$STAT_VERDICT" in
            "IMPROVED")
              STATUS="IMPROVED"
              EMOJI=":rocket:"
              PASS="true"
              VERDICT="Candidate's lower CI ($CANDIDATE_CI_LOWER) > baseline's upper CI ($BASELINE_CI_UPPER) = statistically significant improvement"
              ;;
            "REGRESSION")
              STATUS="REGRESSION"
              EMOJI=":x:"
              PASS="false"
              VERDICT="Candidate's upper CI ($CANDIDATE_CI_UPPER) < baseline's lower CI ($BASELINE_CI_LOWER) = statistically significant regression"
              ;;
            *)
              STATUS="STABLE"
              EMOJI=":white_check_mark:"
              PASS="true"
              VERDICT="CIs overlap = no statistically significant difference (stable)"
              ;;
          esac

          echo "baseline=$BASELINE" >> $GITHUB_OUTPUT
          echo "candidate=$CANDIDATE" >> $GITHUB_OUTPUT
          echo "baseline_ci=$BASELINE_CI" >> $GITHUB_OUTPUT
          echo "candidate_ci=$CANDIDATE_CI" >> $GITHUB_OUTPUT
          echo "baseline_ci_lower=$BASELINE_CI_LOWER" >> $GITHUB_OUTPUT
          echo "baseline_ci_upper=$BASELINE_CI_UPPER" >> $GITHUB_OUTPUT
          echo "candidate_ci_lower=$CANDIDATE_CI_LOWER" >> $GITHUB_OUTPUT
          echo "candidate_ci_upper=$CANDIDATE_CI_UPPER" >> $GITHUB_OUTPUT
          echo "delta=$DELTA_FORMATTED" >> $GITHUB_OUTPUT
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "emoji=$EMOJI" >> $GITHUB_OUTPUT
          echo "pass=$PASS" >> $GITHUB_OUTPUT
          echo "verdict=$VERDICT" >> $GITHUB_OUTPUT

      - name: Comment full evaluation results on PR
        uses: actions/github-script@v7
        with:
          script: |
            const isBootstrapping = '${{ steps.compare.outputs.is_bootstrapping }}' === 'true';
            const baseline = '${{ steps.compare.outputs.baseline }}';
            const candidate = '${{ steps.compare.outputs.candidate }}';
            const baselineCi = '${{ steps.compare.outputs.baseline_ci }}';
            const candidateCi = '${{ steps.compare.outputs.candidate_ci }}';
            const baselineCiLower = '${{ steps.compare.outputs.baseline_ci_lower }}';
            const baselineCiUpper = '${{ steps.compare.outputs.baseline_ci_upper }}';
            const candidateCiLower = '${{ steps.compare.outputs.candidate_ci_lower }}';
            const candidateCiUpper = '${{ steps.compare.outputs.candidate_ci_upper }}';
            const baselineScores = '${{ steps.eval-baseline.outputs.baseline_scores }}';
            const candidateScores = '${{ steps.eval-candidate.outputs.candidate_scores }}';
            const delta = '${{ steps.compare.outputs.delta }}';
            const status = '${{ steps.compare.outputs.status }}';
            const emoji = '${{ steps.compare.outputs.emoji }}';
            const pass = '${{ steps.compare.outputs.pass }}' === 'true';
            const verdict = '${{ steps.compare.outputs.verdict }}';
            const criteria = `${{ steps.eval-candidate.outputs.criteria }}`;

            let body;

            if (isBootstrapping) {
              // Bootstrapping: first wizard installation, no baseline to compare
              body = [
                `## E2E Full Evaluation (Tier 2) ${emoji}`,
                '',
                '_First wizard installation - no baseline to compare against._',
                '',
                '| Metric | Value |',
                '|--------|-------|',
                `| Baseline (main) | N/A (no wizard yet) |`,
                `| Candidate (PR) | ${candidateCi} |`,
                `| 95% CI | [${candidateCiLower}, ${candidateCiUpper}] |`,
                `| Individual Runs | ${candidateScores} |`,
                `| Status | **BOOTSTRAPPING** |`,
                '',
                `### Result: First wizard installation verified (5x evaluation)`,
                '',
                '### Criteria Breakdown (Candidate)',
                criteria,
                '',
                'This PR introduces the wizard for the first time. After merge, future PRs will have a baseline to compare against.',
                '',
                '---',
                '*Bootstrapping mode: Candidate-only evaluation with 5x runs + 95% CI.*'
              ].join('\n');
            } else {
              // Normal comparison mode with statistical CI
              const statusText = {
                'IMPROVED': 'Statistically significant IMPROVEMENT - ready to merge!',
                'STABLE': 'No significant difference - safe to merge',
                'REGRESSION': 'Statistically significant REGRESSION - do not merge'
              }[status] || status;

              body = [
                `## E2E Full Evaluation (Tier 2) ${emoji}`,
                '',
                '_Thorough pre-merge check with 5x evaluation runs + 95% confidence intervals._',
                '',
                '| Metric | Baseline (main) | Candidate (PR) |',
                '|--------|-----------------|----------------|',
                `| Score | ${baselineCi} | ${candidateCi} |`,
                `| 95% CI | [${baselineCiLower}, ${baselineCiUpper}] | [${candidateCiLower}, ${candidateCiUpper}] |`,
                `| Runs | ${baselineScores} | ${candidateScores} |`,
                '',
                `### Statistical Verdict: **${status}** ${emoji}`,
                verdict,
                '',
                `### Status: ${statusText}`,
                '',
                '### Criteria Breakdown (Candidate)',
                criteria,
                '',
                '---',
                '*Tier 2: 5x runs with t-distribution 95% CI. Overlapping CI method for regression detection.*'
              ].join('\n');
            }

            github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });

      - name: Fail on regression
        if: steps.compare.outputs.pass != 'true'
        run: |
          echo "Full E2E evaluation detected a regression"
          echo "Baseline: ${{ steps.compare.outputs.baseline }}"
          echo "Candidate: ${{ steps.compare.outputs.candidate }}"
          echo "Delta: ${{ steps.compare.outputs.delta }}"
          echo "DO NOT MERGE - regression detected"
          exit 1
