name: CI

on:
  pull_request:
  push:
    branches: [main]

permissions:
  contents: read
  pull-requests: write
  id-token: write

jobs:
  validate:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Validate YAML workflows
        run: |
          echo "Validating workflow YAML files..."
          for file in .github/workflows/*.yml; do
            echo "Checking $file"
            python3 -c "import yaml; yaml.safe_load(open('$file'))" || exit 1
          done
          echo "All workflow files are valid YAML"

      - name: Shellcheck scripts in workflows
        run: |
          echo "Checking for shell script issues in workflows..."
          # Extract and check run blocks from workflows
          # This is a basic check - shellcheck would be better but requires install
          for file in .github/workflows/*.yml; do
            echo "Scanning $file for common issues..."
            # Check for unsafe variable interpolation (the bug we fixed)
            if grep -E "='\\$\\{\\{.*\\}\\}'" "$file"; then
              echo "WARNING: Found potentially unsafe variable interpolation in $file"
              echo "Use env: block + file writes instead"
              exit 1
            fi
          done
          echo "No obvious shell issues found"

      - name: Validate prompt files exist
        run: |
          echo "Checking required prompt files..."
          test -f .github/prompts/analyze-release.md || (echo "Missing analyze-release.md" && exit 1)
          test -f .github/prompts/analyze-community.md || (echo "Missing analyze-community.md" && exit 1)
          echo "All prompt files present"

      - name: Validate state files
        run: |
          echo "Checking state files..."
          test -f .github/last-checked-version.txt || (echo "Missing last-checked-version.txt" && exit 1)
          test -f .github/last-community-scan.txt || (echo "Missing last-community-scan.txt" && exit 1)
          echo "All state files present"

      - name: Run version logic tests
        run: ./tests/test-version-logic.sh

      - name: Run analysis schema tests
        run: ./tests/test-analysis-schema.sh

      - name: Run workflow trigger tests
        run: ./tests/test-workflow-triggers.sh

      - name: Validate E2E fixtures and scenarios
        run: ./tests/e2e/run-simulation.sh

  # Clean up old bot comments on PR push (keeps PRs tidy)
  cleanup-old-comments:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    steps:
      - name: Resolve outdated bot comments
        uses: int128/hide-comment-action@v1
        with:
          # Hide (collapse) old bot comments when new push arrives
          # Human comments are preserved
          authors: 'github-actions[bot]'
          starts-with: |
            ## E2E SDLC Evaluation
            ## E2E Before/After Comparison
            ## PR Code Review
            **Claude finished

  # TIER 1: Quick E2E Check - Runs on every PR commit
  # Single comparison: baseline vs candidate (1x each)
  # Purpose: Fast quality gate to catch regressions early
  e2e-quick-check:
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    needs: [validate, cleanup-old-comments]

    steps:
      - name: Checkout PR branch
        uses: actions/checkout@v4
        with:
          path: pr-branch

      - name: Checkout main branch for baseline
        uses: actions/checkout@v4
        with:
          ref: main
          path: main-branch

      - name: Install BASELINE wizard (main branch) into test fixture
        run: |
          echo "Installing main branch wizard into test fixture..."
          # Create .claude directory in test fixture
          mkdir -p pr-branch/tests/e2e/fixtures/test-repo/.claude
          # Copy main branch wizard files
          cp -r main-branch/.claude/hooks pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp -r main-branch/.claude/skills pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp main-branch/.claude/settings.json pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          echo "Baseline wizard installed:"
          ls -la pr-branch/tests/e2e/fixtures/test-repo/.claude/ || echo "No .claude directory"

      - name: Run BASELINE simulation with Claude
        id: baseline
        uses: anthropics/claude-code-action@v1
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          working_directory: pr-branch/tests/e2e/fixtures/test-repo
          claude_args: |
            --max-turns 30
            --allowedTools "Read,Edit,Write,Bash(npm *),Bash(node *)"
          prompt: |
            Run an E2E SDLC simulation using scenario: ../../scenarios/medium-add-feature.md

            1. Read the scenario file to understand the task
            2. Execute the scenario task following SDLC principles
            3. Return results as JSON with score

            After execution, output a summary of what you did and whether SDLC was followed.

      - name: Evaluate BASELINE
        id: eval-baseline
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        working-directory: pr-branch
        run: |
          OUTPUT_FILE="/home/runner/work/_temp/claude-execution-output.json"
          SCENARIO="tests/e2e/scenarios/medium-add-feature.md"

          if [ ! -f "$OUTPUT_FILE" ]; then
            echo "baseline_score=0" >> $GITHUB_OUTPUT
            echo "baseline_status=fail" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Run evaluation
          RESULT=$(./tests/e2e/evaluate.sh "$SCENARIO" "$OUTPUT_FILE" --json 2>&1) || true

          if echo "$RESULT" | jq -e '.score' > /dev/null 2>&1; then
            SCORE=$(echo "$RESULT" | jq -r '.score // 0')
          else
            SCORE="0"
          fi

          echo "Baseline score: $SCORE"
          echo "baseline_score=$SCORE" >> $GITHUB_OUTPUT

          # Save output for comparison
          cp "$OUTPUT_FILE" "/tmp/baseline-output.json" 2>/dev/null || true

      - name: Reset test fixture for CANDIDATE
        run: |
          echo "Resetting test fixture..."
          cd pr-branch/tests/e2e/fixtures/test-repo
          # Remove any changes Claude made
          git checkout -- . 2>/dev/null || true
          git clean -fd 2>/dev/null || true
          # Remove old wizard
          rm -rf .claude

      - name: Install CANDIDATE wizard (PR branch) into test fixture
        run: |
          echo "Installing PR branch wizard into test fixture..."
          mkdir -p pr-branch/tests/e2e/fixtures/test-repo/.claude
          # Copy PR branch wizard files
          cp -r pr-branch/.claude/hooks pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp -r pr-branch/.claude/skills pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp pr-branch/.claude/settings.json pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          echo "Candidate wizard installed:"
          ls -la pr-branch/tests/e2e/fixtures/test-repo/.claude/ || echo "No .claude directory"

      - name: Run CANDIDATE simulation with Claude
        id: candidate
        uses: anthropics/claude-code-action@v1
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          working_directory: pr-branch/tests/e2e/fixtures/test-repo
          claude_args: |
            --max-turns 30
            --allowedTools "Read,Edit,Write,Bash(npm *),Bash(node *)"
          prompt: |
            Run an E2E SDLC simulation using scenario: ../../scenarios/medium-add-feature.md

            1. Read the scenario file to understand the task
            2. Execute the scenario task following SDLC principles
            3. Return results as JSON with score

            After execution, output a summary of what you did and whether SDLC was followed.

      - name: Evaluate CANDIDATE
        id: eval-candidate
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        working-directory: pr-branch
        run: |
          OUTPUT_FILE="/home/runner/work/_temp/claude-execution-output.json"
          SCENARIO="tests/e2e/scenarios/medium-add-feature.md"

          if [ ! -f "$OUTPUT_FILE" ]; then
            echo "candidate_score=0" >> $GITHUB_OUTPUT
            echo "candidate_status=fail" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Run evaluation
          RESULT=$(./tests/e2e/evaluate.sh "$SCENARIO" "$OUTPUT_FILE" --json 2>&1) || true

          if echo "$RESULT" | jq -e '.score' > /dev/null 2>&1; then
            SCORE=$(echo "$RESULT" | jq -r '.score // 0')
          else
            SCORE="0"
          fi

          echo "Candidate score: $SCORE"
          echo "candidate_score=$SCORE" >> $GITHUB_OUTPUT

      - name: Compare scores
        id: compare
        run: |
          BASELINE="${{ steps.eval-baseline.outputs.baseline_score }}"
          CANDIDATE="${{ steps.eval-candidate.outputs.candidate_score }}"

          # Default to 0 if empty
          BASELINE=${BASELINE:-0}
          CANDIDATE=${CANDIDATE:-0}

          # Calculate delta using bc for float math
          DELTA=$(echo "$CANDIDATE - $BASELINE" | bc -l)
          DELTA_FORMATTED=$(printf "%.1f" "$DELTA")

          echo "Baseline: $BASELINE"
          echo "Candidate: $CANDIDATE"
          echo "Delta: $DELTA_FORMATTED"

          # Determine status
          if [ "$(echo "$DELTA >= 0" | bc -l)" -eq 1 ]; then
            if [ "$(echo "$DELTA > 0" | bc -l)" -eq 1 ]; then
              STATUS="IMPROVED"
              EMOJI=":arrow_up:"
            else
              STATUS="UNCHANGED"
              EMOJI=":white_check_mark:"
            fi
            PASS="true"
          else
            # Check if regression is significant (> 0.5 points)
            if [ "$(echo "$DELTA < -0.5" | bc -l)" -eq 1 ]; then
              STATUS="REGRESSION"
              EMOJI=":x:"
              PASS="false"
            else
              STATUS="MINOR_DIP"
              EMOJI=":warning:"
              PASS="true"  # Minor dips within variance are acceptable
            fi
          fi

          echo "baseline=$BASELINE" >> $GITHUB_OUTPUT
          echo "candidate=$CANDIDATE" >> $GITHUB_OUTPUT
          echo "delta=$DELTA_FORMATTED" >> $GITHUB_OUTPUT
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "emoji=$EMOJI" >> $GITHUB_OUTPUT
          echo "pass=$PASS" >> $GITHUB_OUTPUT

      - name: Comment quick check results on PR
        uses: actions/github-script@v7
        with:
          script: |
            const baseline = '${{ steps.compare.outputs.baseline }}';
            const candidate = '${{ steps.compare.outputs.candidate }}';
            const delta = '${{ steps.compare.outputs.delta }}';
            const status = '${{ steps.compare.outputs.status }}';
            const emoji = '${{ steps.compare.outputs.emoji }}';
            const pass = '${{ steps.compare.outputs.pass }}' === 'true';

            const statusText = {
              'IMPROVED': 'Wizard changes IMPROVED SDLC compliance!',
              'UNCHANGED': 'No change in SDLC compliance (stable)',
              'MINOR_DIP': 'Minor variance detected (within acceptable range)',
              'REGRESSION': 'REGRESSION: Wizard changes reduced SDLC compliance'
            }[status] || status;

            const body = [
              `## E2E Quick Check (Tier 1) ${emoji}`,
              '',
              '_Fast quality gate - single comparison per commit._',
              '',
              '| Metric | Value |',
              '|--------|-------|',
              `| Baseline (main) | ${baseline} / 10 |`,
              `| Candidate (PR) | ${candidate} / 10 |`,
              `| Delta | ${delta >= 0 ? '+' : ''}${delta} |`,
              `| Status | **${status}** |`,
              '',
              `### Result: ${statusText}`,
              '',
              '_Add `merge-ready` label for full 3x evaluation before merge._',
              '',
              '---',
              '*Tier 1: 1x run each. Tier 2: 3x runs averaged for statistical confidence.*'
            ].join('\n');

            github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });

      - name: Fail on regression
        if: steps.compare.outputs.pass != 'true'
        run: |
          echo "E2E quick check detected a regression"
          echo "Baseline: ${{ steps.compare.outputs.baseline }}"
          echo "Candidate: ${{ steps.compare.outputs.candidate }}"
          echo "Delta: ${{ steps.compare.outputs.delta }}"
          exit 1

  # TIER 2: Full E2E Evaluation - Runs before merge
  # 3x evaluations each, averaged for statistical confidence
  # Triggered by: merge-ready label
  e2e-full-evaluation:
    runs-on: ubuntu-latest
    if: |
      github.event_name == 'pull_request' &&
      contains(github.event.pull_request.labels.*.name, 'merge-ready')
    needs: [validate, cleanup-old-comments]

    steps:
      - name: Checkout PR branch
        uses: actions/checkout@v4
        with:
          path: pr-branch

      - name: Checkout main branch for baseline
        uses: actions/checkout@v4
        with:
          ref: main
          path: main-branch

      - name: Install BASELINE wizard (main branch) into test fixture
        run: |
          echo "Installing main branch wizard into test fixture..."
          mkdir -p pr-branch/tests/e2e/fixtures/test-repo/.claude
          cp -r main-branch/.claude/hooks pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp -r main-branch/.claude/skills pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp main-branch/.claude/settings.json pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true

      - name: Run BASELINE simulation with Claude
        id: baseline
        uses: anthropics/claude-code-action@v1
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          working_directory: pr-branch/tests/e2e/fixtures/test-repo
          claude_args: |
            --max-turns 30
            --allowedTools "Read,Edit,Write,Bash(npm *),Bash(node *)"
          prompt: |
            Run an E2E SDLC simulation using scenario: ../../scenarios/medium-add-feature.md

            1. Read the scenario file to understand the task
            2. Execute the scenario task following SDLC principles
            3. Return results as JSON with score

            After execution, output a summary of what you did and whether SDLC was followed.

      - name: Evaluate BASELINE (3x for variance reduction)
        id: eval-baseline
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        working-directory: pr-branch
        run: |
          OUTPUT_FILE="/home/runner/work/_temp/claude-execution-output.json"
          SCENARIO="tests/e2e/scenarios/medium-add-feature.md"

          if [ ! -f "$OUTPUT_FILE" ]; then
            echo "baseline_score=0" >> $GITHUB_OUTPUT
            echo "baseline_scores=0 0 0" >> $GITHUB_OUTPUT
            echo "baseline_std=0" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Run evaluation 3x for variance reduction
          echo "Running baseline evaluation 3 times..."
          SCORES=""
          for i in 1 2 3; do
            echo "Baseline evaluation run $i/3..."
            RESULT=$(./tests/e2e/evaluate.sh "$SCENARIO" "$OUTPUT_FILE" --json 2>&1) || true
            if echo "$RESULT" | jq -e '.score' > /dev/null 2>&1; then
              SCORE=$(echo "$RESULT" | jq -r '.score // 0')
            else
              SCORE="0"
            fi
            SCORES="$SCORES $SCORE"
            echo "  Run $i score: $SCORE"
            sleep 1
          done

          # Calculate average and std dev
          AVG=$(echo "$SCORES" | awk '{sum=0; for(i=1;i<=NF;i++) sum+=$i; printf "%.1f", sum/NF}')
          STD=$(echo "$SCORES" | awk -v avg="$AVG" '{sum=0; for(i=1;i<=NF;i++) sum+=($i-avg)^2; printf "%.1f", sqrt(sum/NF)}')
          SCORES_DISPLAY=$(echo "$SCORES" | sed 's/^ //')

          echo "Baseline: $AVG (+/- $STD) from [$SCORES_DISPLAY]"
          echo "baseline_score=$AVG" >> $GITHUB_OUTPUT
          echo "baseline_scores=$SCORES_DISPLAY" >> $GITHUB_OUTPUT
          echo "baseline_std=$STD" >> $GITHUB_OUTPUT

          cp "$OUTPUT_FILE" "/tmp/baseline-output.json" 2>/dev/null || true

      - name: Reset test fixture for CANDIDATE
        run: |
          cd pr-branch/tests/e2e/fixtures/test-repo
          git checkout -- . 2>/dev/null || true
          git clean -fd 2>/dev/null || true
          rm -rf .claude

      - name: Install CANDIDATE wizard (PR branch) into test fixture
        run: |
          mkdir -p pr-branch/tests/e2e/fixtures/test-repo/.claude
          cp -r pr-branch/.claude/hooks pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp -r pr-branch/.claude/skills pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true
          cp pr-branch/.claude/settings.json pr-branch/tests/e2e/fixtures/test-repo/.claude/ 2>/dev/null || true

      - name: Run CANDIDATE simulation with Claude
        id: candidate
        uses: anthropics/claude-code-action@v1
        with:
          anthropic_api_key: ${{ secrets.ANTHROPIC_API_KEY }}
          github_token: ${{ secrets.GITHUB_TOKEN }}
          working_directory: pr-branch/tests/e2e/fixtures/test-repo
          claude_args: |
            --max-turns 30
            --allowedTools "Read,Edit,Write,Bash(npm *),Bash(node *)"
          prompt: |
            Run an E2E SDLC simulation using scenario: ../../scenarios/medium-add-feature.md

            1. Read the scenario file to understand the task
            2. Execute the scenario task following SDLC principles
            3. Return results as JSON with score

            After execution, output a summary of what you did and whether SDLC was followed.

      - name: Evaluate CANDIDATE (3x for variance reduction)
        id: eval-candidate
        env:
          ANTHROPIC_API_KEY: ${{ secrets.ANTHROPIC_API_KEY }}
        working-directory: pr-branch
        run: |
          OUTPUT_FILE="/home/runner/work/_temp/claude-execution-output.json"
          SCENARIO="tests/e2e/scenarios/medium-add-feature.md"

          if [ ! -f "$OUTPUT_FILE" ]; then
            echo "candidate_score=0" >> $GITHUB_OUTPUT
            echo "candidate_scores=0 0 0" >> $GITHUB_OUTPUT
            echo "candidate_std=0" >> $GITHUB_OUTPUT
            exit 0
          fi

          # Run evaluation 3x for variance reduction
          echo "Running candidate evaluation 3 times..."
          SCORES=""
          LAST_RESULT=""
          for i in 1 2 3; do
            echo "Candidate evaluation run $i/3..."
            RESULT=$(./tests/e2e/evaluate.sh "$SCENARIO" "$OUTPUT_FILE" --json 2>&1) || true
            if echo "$RESULT" | jq -e '.score' > /dev/null 2>&1; then
              SCORE=$(echo "$RESULT" | jq -r '.score // 0')
            else
              SCORE="0"
            fi
            SCORES="$SCORES $SCORE"
            LAST_RESULT="$RESULT"
            echo "  Run $i score: $SCORE"
            sleep 1
          done

          # Calculate average and std dev
          AVG=$(echo "$SCORES" | awk '{sum=0; for(i=1;i<=NF;i++) sum+=$i; printf "%.1f", sum/NF}')
          STD=$(echo "$SCORES" | awk -v avg="$AVG" '{sum=0; for(i=1;i<=NF;i++) sum+=($i-avg)^2; printf "%.1f", sqrt(sum/NF)}')
          SCORES_DISPLAY=$(echo "$SCORES" | sed 's/^ //')

          echo "Candidate: $AVG (+/- $STD) from [$SCORES_DISPLAY]"
          echo "candidate_score=$AVG" >> $GITHUB_OUTPUT
          echo "candidate_scores=$SCORES_DISPLAY" >> $GITHUB_OUTPUT
          echo "candidate_std=$STD" >> $GITHUB_OUTPUT

          # Extract criteria breakdown from last result
          CRITERIA=$(echo "$LAST_RESULT" | jq -r '.criteria | to_entries | map("- **\(.key)**: \(.value.points)/\(.value.max)") | join("\n")' 2>/dev/null || echo "Could not parse criteria")
          {
            echo "criteria<<EOF"
            echo "$CRITERIA"
            echo "EOF"
          } >> $GITHUB_OUTPUT

      - name: Compare scores (full evaluation)
        id: compare
        run: |
          BASELINE="${{ steps.eval-baseline.outputs.baseline_score }}"
          CANDIDATE="${{ steps.eval-candidate.outputs.candidate_score }}"
          BASELINE_STD="${{ steps.eval-baseline.outputs.baseline_std }}"
          CANDIDATE_STD="${{ steps.eval-candidate.outputs.candidate_std }}"

          BASELINE=${BASELINE:-0}
          CANDIDATE=${CANDIDATE:-0}

          DELTA=$(echo "$CANDIDATE - $BASELINE" | bc -l)
          DELTA_FORMATTED=$(printf "%.1f" "$DELTA")

          echo "Baseline: $BASELINE (+/- $BASELINE_STD)"
          echo "Candidate: $CANDIDATE (+/- $CANDIDATE_STD)"
          echo "Delta: $DELTA_FORMATTED"

          # For full evaluation, be stricter about regression
          if [ "$(echo "$DELTA >= 0" | bc -l)" -eq 1 ]; then
            if [ "$(echo "$DELTA > 0.5" | bc -l)" -eq 1 ]; then
              STATUS="IMPROVED"
              EMOJI=":rocket:"
            else
              STATUS="STABLE"
              EMOJI=":white_check_mark:"
            fi
            PASS="true"
          else
            # Any regression in full eval is a fail
            STATUS="REGRESSION"
            EMOJI=":x:"
            PASS="false"
          fi

          echo "baseline=$BASELINE" >> $GITHUB_OUTPUT
          echo "candidate=$CANDIDATE" >> $GITHUB_OUTPUT
          echo "baseline_std=$BASELINE_STD" >> $GITHUB_OUTPUT
          echo "candidate_std=$CANDIDATE_STD" >> $GITHUB_OUTPUT
          echo "delta=$DELTA_FORMATTED" >> $GITHUB_OUTPUT
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "emoji=$EMOJI" >> $GITHUB_OUTPUT
          echo "pass=$PASS" >> $GITHUB_OUTPUT

      - name: Comment full evaluation results on PR
        uses: actions/github-script@v7
        with:
          script: |
            const baseline = '${{ steps.compare.outputs.baseline }}';
            const candidate = '${{ steps.compare.outputs.candidate }}';
            const baselineStd = '${{ steps.compare.outputs.baseline_std }}';
            const candidateStd = '${{ steps.compare.outputs.candidate_std }}';
            const baselineScores = '${{ steps.eval-baseline.outputs.baseline_scores }}';
            const candidateScores = '${{ steps.eval-candidate.outputs.candidate_scores }}';
            const delta = '${{ steps.compare.outputs.delta }}';
            const status = '${{ steps.compare.outputs.status }}';
            const emoji = '${{ steps.compare.outputs.emoji }}';
            const pass = '${{ steps.compare.outputs.pass }}' === 'true';
            const criteria = `${{ steps.eval-candidate.outputs.criteria }}`;

            const statusText = {
              'IMPROVED': 'Wizard IMPROVED SDLC compliance - ready to merge!',
              'STABLE': 'No regression detected - safe to merge',
              'REGRESSION': 'REGRESSION detected - do not merge'
            }[status] || status;

            const body = [
              `## E2E Full Evaluation (Tier 2) ${emoji}`,
              '',
              '_Thorough pre-merge check with 3x evaluation runs for statistical confidence._',
              '',
              '| Metric | Baseline (main) | Candidate (PR) |',
              '|--------|-----------------|----------------|',
              `| Average Score | ${baseline} +/- ${baselineStd} | ${candidate} +/- ${candidateStd} |`,
              `| Individual Runs | ${baselineScores} | ${candidateScores} |`,
              `| Delta | | **${delta >= 0 ? '+' : ''}${delta}** |`,
              '',
              `### Status: **${status}** - ${statusText}`,
              '',
              '### Criteria Breakdown (Candidate)',
              criteria,
              '',
              '---',
              '*Tier 2: 3x runs averaged. Statistical confidence for merge decisions.*'
            ].join('\n');

            github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: body
            });

      - name: Fail on regression
        if: steps.compare.outputs.pass != 'true'
        run: |
          echo "Full E2E evaluation detected a regression"
          echo "Baseline: ${{ steps.compare.outputs.baseline }}"
          echo "Candidate: ${{ steps.compare.outputs.candidate }}"
          echo "Delta: ${{ steps.compare.outputs.delta }}"
          echo "DO NOT MERGE - regression detected"
          exit 1
